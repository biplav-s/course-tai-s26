<em> **See also** : 
readings in [Large Language Models (LLMs)](./Readme-LLMs.md) and [AI Trust](./Readme-Trust.md) </em>

---

1. Introduction to AI concepts
> 1. [Understanding AI and Cognitive Systems - a Perspective on Its Potential and Challenges While Putting Them to Work with People](https://journal.accsindia.org/show.article.php?id=81), AI Cognitive Systems, Issue 4, Vol 2- Issue 1 (2018)
> 2. [A Perspectival Mirror of the Elephant: Investigating language bias on Google, ChatGPT, YouTube, and Wikipedia](https://cacm.acm.org/practice/a-perspectival-mirror-of-the-elephant/), Communications of the ACM, July 2024.
> 3. [Large Language Models Pass the Turing Test](https://arxiv.org/abs/2503.23674), April 2025. _Describes systematic experimentation to evaluate performance of LLMs and rule-based Eliza on the 3-party Turing test_. 

2. Tools and libraries for processing text
> 1. [NLTK](https://www.nltk.org/) -  a large library of NLP methods.
> 2. [Spacy](https://spacy.io/) - an efficient, although limited, set of NLP Methods.
> 3. [CoreNLP](https://stanfordnlp.github.io/CoreNLP/) - an efficient set of NLP methods in Java
> 4. Online visualization tools:
> > a. Tokenization: https://platform.openai.com/tokenizer
> > 
> > b. Parts of speech: https://parts-of-speech.info/, https://corenlp.run/
> > 
> > c. Edit distance: https://phiresky.github.io/levenshtein-demo/
 
3. Evaluating text 
> 1. Comparing strings and outputs of LLMs [A list of metrics for evaluating LLM-generated content](https://learn.microsoft.com/en-us/ai/playbook/technology-guidance/generative-ai/working-with-llms/evaluation/list-of-eval-metrics), 
Microsoft, June 2024
> 2. [Evaluating Large Language Model (LLM) systems: Metrics, challenges, and best practices](https://medium.com/data-science-at-microsoft/evaluating-llm-systems-metrics-challenges-and-best-practices-664ac25be7e5), Jane Huang, March 2024

4. NLP Concepts
> 1. Topic modeling: [Latent Semantic Analysis](https://www.analyticsvidhya.com/blog/2018/10/stepwise-guide-topic-modeling-latent-semantic-analysis/) (LSA), 2024 by Prateek, Analytics Vidhya; [Latent Drichlet Allocation](https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/) (LDA), 2024 by Analytics Vidhya. 

> 2. Text classification, learning: 
Shervin Minaee, Nal Kalchbrenner, Erik Cambria, Narjes Nikzad, Meysam Chenaghlu, and Jianfeng Gao. 2021. [Deep Learning--based Text Classification: A Comprehensive Review](https://dl.acm.org/doi/abs/10.1145/3439726). ACM Comput. Surv. 54, 3, Article 62 (April 2022), 40 pages. https://doi.org/10.1145/3439726

5. AI, language and human understanding
> 1. [AI And The Limits Of Language](https://www.noemamag.com/ai-and-the-limits-of-language/),  Jacob Browning and Yann LeCun, Aug 2022. _Argues that not all human knowledge is in text, and so, any AI trained on it will struggle_.
> 2. Weidinger, Laura, et al., [Taxonomy of Risks posed by Language Models](https://dl.acm.org/doi/10.1145/3531146.3533088), 2022 ACM Conference on Fairness, Accountability, and Transparency.
> 3. [Mission: Impossible Language Models](https://aclanthology.org/2024.acl-long.787/), Julie Kallini, Isabel Papadimitriou, et al, ACL 2024. _Creates impossible languages and sees how GPT-2 performs on them. Implication for grammards and language learning._
> 4. AI slop - low quality automatically generated output. [What is AI slop? A technologist explains this new and largely unwelcome form of online content](https://theconversation.com/what-is-ai-slop-a-technologist-explains-this-new-and-largely-unwelcome-form-of-online-content-256554), Sep 2025.

6. Resources: Datasets, Packages, Courses
> 1. Data - [Introduction to the CoNLL-2002 Shared Task: Language-Independent Named Entity Recognition](https://aclanthology.org/W02-2024/). Extraction in Dutch and Spanish.
> 2. Data - [Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition](https://paperswithcode.com/dataset/conll-2003). Extraction in English and German.
> 3. Packages - See [Useful NLP Packages](https://github.com/biplav-s/course-nl/blob/8f0bb9e50db6706595e6d5ca38c39d31e9bfc77b/resources/UsefulNLPPackages.md) resources from CSCE 771 - Fall 2020
> 4. Courses - Stanford course - [CS 324 - Advances in Foundation Models](https://stanford-cs324.github.io/winter2023/syllabus/), USC course - [CSCE 771 - Computer Processing of Natural Languages](https://sites.google.com/site/biplavsrivastava/teaching/csce-771-computer-processing-of-natural-language)
> 5. Blogs explaining LLM concepts
> > a. Training LLMs and related concepts - [The Novice's LLM Training Guide](https://rentry.org/llm-training).
> > 
> > b. Estimating computing cost of LLM training - [Transformer Math 101](https://blog.eleuther.ai/transformer-math/), in EleutherAI Blog, Apr 2023.
> > 
> > c. Understanding Transformers - [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)

7. NLP Applications
> 1. Yufeng Huang, Mariana Bernagozzi, Michelle Morales, Sheema Usmani, Biplav Srivastava, Michelle Mullins, [Clarity 2.0: Improved Assessment of Product Competitiveness from Online Content](https://ojs.aaai.org/index.php/aimagazine/article/view/15100). AI Mag. 42(2): 59-70 (2021)
> 2. [Artificial intelligence is helping scientists decode animal languages](https://www.popsci.com/technology/artificial-intelligence-animal-language/), Charlotte Hu, Popular Science, Sep 2022, 
